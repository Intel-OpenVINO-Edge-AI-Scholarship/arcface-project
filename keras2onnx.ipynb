{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras2onnx\n",
    "import onnxruntime\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.datasets import mnist\n",
    "from metrics_face import *\n",
    "import tensorflow.compat.v1 as tf\n",
    "from glob import glob\n",
    "import os\n",
    "import facenet\n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y), (X_test, y_test) = mnist.load_data()\n",
    "X = X[:, :, :, np.newaxis].astype('float32') / 255\n",
    "X_test = X_test[:, :, :, np.newaxis].astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    img = image.load_img(img_path, target_size=(160, 160))\n",
    "    return np.expand_dims(np.asarray(img),axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, nrof_classes = facenet.get_dataset(\"vggface2_train_2/train\")\n",
    "path_exp = os.path.expanduser(\"vggface2_train_2/train\")\n",
    "image_paths = [glob(os.path.join(path_exp, classes[i], \"*.jpg\")) for i in range(nrof_classes)]\n",
    "split = int(round(nrof_classes*(1-0.99)))\n",
    "X_test = paths_to_tensor([image_paths[0][0],image_paths[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, nrof_classes = facenet.get_dataset(\"vggface2_test_2/test\")\n",
    "nrof_classes = 30\n",
    "np.random.shuffle(classes)\n",
    "path_exp = os.path.expanduser(\"vggface2_test_2/test\")\n",
    "image_paths = [sorted(glob(os.path.join(path_exp, classes[i], \"*.jpg\")))[3:4] for i in range(nrof_classes)]\n",
    "images = []\n",
    "image_paths = np.array(image_paths).flatten().tolist()\n",
    "for img_path in tqdm(image_paths):\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    face_cascade = cv2.CascadeClassifier('/usr/share/opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "    img = np.asarray(img)\n",
    "    faces_multi = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "    faces = [face.astype(np.int64).tolist() for face in faces_multi]\n",
    "    if len(faces) > 0:\n",
    "        yes_face = faces[0]\n",
    "        img = cv2.resize(img[yes_face[1]:yes_face[1]+yes_face[3],yes_face[0]:yes_face[0]+yes_face[2]],(160,160))\n",
    "        images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_model = load_model('models/mnist_vgg8_arcface_5d/model_sm.hdf5', custom_objects={'ArcFace': ArcFace})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "arcface_model1 = Model(inputs=arcface_model.input[0], outputs=arcface_model.layers[-4].output)\n",
    "arcface_features1_array = []\n",
    "for img in tqdm(images):\n",
    "    arcface_features1 = arcface_model1.predict(img.reshape(1,160,160,1), verbose=1)\n",
    "    arcface_features1_array.append(arcface_features1/np.linalg.norm(arcface_features1, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [1, 0.5, 1, 10, 10]\n",
    "def intermediate_model(x):\n",
    "    return keras.backend.max(x, axis=1) * \\\n",
    "(keras.activations.elu((x-keras.backend.mean(x, axis=1))/keras.backend.square(keras.backend.std(x)))+\\\n",
    "    keras.backend.square(x-keras.backend.mean(x, axis=1))/keras.backend.std(x)) + \\\n",
    "keras.backend.min(x, axis=1) * keras.backend.log(keras.backend.square(x-keras.backend.mean(x, axis=1)))\n",
    "intermediary_array = []\n",
    "for i in tqdm(range(len(images))):\n",
    "    a = np.multiply(class_weights, intermediate_model(\n",
    "        tf.convert_to_tensor(tf.convert_to_tensor(arcface_features1_array[i], dtype=tf.float32))).numpy())\n",
    "    if i < 10:\n",
    "        print(a)\n",
    "    intermediary_array.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xc2 in position 2: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-41b0b70c029b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/retina-net-R-101-FPN/model_final.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc2 in position 2: ordinal not in range(128)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediary_array = np.dstack(intermediary_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ 0.11949151, -0.7965891 ,  0.26912665,  0.44944108,  0.27702197]\n",
    "[ 0.1343845 , -0.6959256 ,  0.10052601, -0.57591254,  0.39477533]\n",
    "[-0.20688158,  0.79289556, -0.17721854,  0.4884938 , -0.24183482]\n",
    "[-0.23509903,  0.7068529 , -0.20450296,  0.50083554, -0.39042255]\n",
    "[-0.27845502,  0.6834492 , -0.0885547 , -0.2526008 , -0.61944395]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = arcface_model.layers[-3].weights[0]\n",
    "beta = arcface_model.layers[-3].weights[1]\n",
    "moving_mean = arcface_model.layers[-3].weights[2]\n",
    "moving_variance = arcface_model.layers[-3].weights[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma.numpy(), beta.numpy(), moving_mean.numpy(), moving_variance.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xNorm = (intermediary_array[0,:,:] - moving_mean.numpy().reshape(-1,1)) / np.sqrt(0.001 + moving_variance.numpy().reshape(-1,1))\n",
    "data = gamma.numpy().reshape(-1,1) * xNorm + beta.numpy().reshape(-1,1)\n",
    "np.round(data.T/np.linalg.norm(data.T,1),7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_features2_array = np.dstack(arcface_features2_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_model2 = Model(inputs=arcface_model.input[0], outputs=arcface_model.layers[-3].output)\n",
    "arcface_features2_array = []\n",
    "for img in tqdm(images):\n",
    "    arcface_features2 = arcface_model2.predict(img.reshape(1,160,160,1), verbose=1)\n",
    "    arcface_features2_array.append(arcface_features2/np.linalg.norm(arcface_features2, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = [-0.176519  , -0.105028  ,  0.95071614, -0.21184155, -0.09524728]\n",
    "p2 = [-0.17389667, -0.10519306,  0.93706113, -0.26787877, -0.09408321]\n",
    "p3 = [-0.17534307, -0.09559851,  0.9498372 , -0.2157349 , -0.1066931 ]\n",
    "p4 = [-0.17858912, -0.09505837,  0.9690808 , -0.09122588, -0.10784248]\n",
    "p5 = [-0.17978127, -0.1065986 ,  0.9706176 , -0.04294081, -0.11123333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(librosa.istft(np.dstack([p1]*5).reshape(-1,5), hop_length=1, win_length=1))\n",
    "print(librosa.istft(np.dstack([p2]*5).reshape(-1,5), hop_length=1, win_length=1))\n",
    "print(librosa.istft(np.dstack([p3]*5).reshape(-1,5), hop_length=1, win_length=1))\n",
    "print(librosa.istft(np.dstack([p4]*5).reshape(-1,5), hop_length=1, win_length=1))\n",
    "print(librosa.istft(np.dstack([p5]*5).reshape(-1,5), hop_length=1, win_length=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from pandas.plotting import andrews_curves\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# Look pretty...\n",
    "matplotlib.style.use('ggplot')\n",
    "# If the above line throws an error, use plt.style.use('ggplot') instead\n",
    "\n",
    "# Load up SKLearn's Iris Dataset into a Pandas Dataframe\n",
    "class_weights = [0.1, 0.5, 0.1, 1, 1]\n",
    "df = pd.DataFrame(\n",
    "    np.multiply(class_weights, \n",
    "      np.exp(arcface_features1_array-np.expand_dims(arcface_features1_array.mean(axis=1),1)/\\\n",
    "      np.expand_dims(arcface_features1_array.std(axis=1),1)) + \\\n",
    "    np.expand_dims(arcface_features1_array.mean(axis=1),1)\n",
    "   ), columns=['col1','col2','col3','col4','col5'])\n",
    "df['target_names'] = [librosa.istft(\n",
    "    np.dstack([df.iloc[i,:].values]*5).reshape(-1,5), hop_length=1, win_length=1\n",
    ").mean() for i in range(len(df))]\n",
    "# Andrews Curves Start Here:\n",
    "plt.figure()\n",
    "andrews_curves(df, 'target_names')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[-0.17978127, -0.1065986 ,  0.9706176 , -0.04294081, -0.11123333]\n",
    "[-0.17668884, -0.11009184,  0.93734115, -0.26282188, -0.09474736]\n",
    "[-0.1755625 , -0.05969939,  0.97241575, -0.011096  , -0.14106144]\n",
    "[-0.17391324, -0.05885269,  0.9708331 ,  0.01058049, -0.15382384]\n",
    "[-0.17508644, -0.07741634,  0.96141636, -0.14232956, -0.13701247]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = [-0.176519  , -0.105028  ,  0.95071614, -0.21184155, -0.09524728]\n",
    "p2 = [-0.17389667, -0.10519306,  0.93706113, -0.26787877, -0.09408321]\n",
    "p3 = [-0.17534307, -0.09559851,  0.9498372 , -0.2157349 , -0.1066931 ]\n",
    "p4 = [-0.17858912, -0.09505837,  0.9690808 , -0.09122588, -0.10784248]\n",
    "p5 = [-0.17978127, -0.1065986 ,  0.9706176 , -0.04294081, -0.11123333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from pandas.tools.plotting import andrews_curves\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# Look pretty...\n",
    "matplotlib.style.use('ggplot')\n",
    "# If the above line throws an error, use plt.style.use('ggplot') instead\n",
    "\n",
    "# Load up SKLearn's Iris Dataset into a Pandas Dataframe\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target_names'] = [data.target_names[i] for i in data.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(arcface_features2_array, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagehash.average_hash(\n",
    "    Image.open(\"vggface2_test/test/n000029/0130_01.jpg\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagehash, cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(1580, 862),\n",
    "        batch_size=32)\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(1580, 862),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure()\n",
    "ax2 = Axes3D(fig2)\n",
    "for c in range(len(np.unique(y_test))):\n",
    "    ax2.plot(arcface_features[y_test==c, 0], arcface_features[y_test==c, 1], arcface_features[y_test==c, 2], '.', alpha=0.1)\n",
    "plt.title('ArcFace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(librosa.istft(np.array([p1]*3).reshape(-1,3), hop_length=1, win_length=3))\n",
    "print(librosa.istft(np.array([p2]*3).reshape(-1,3), hop_length=1, win_length=3))\n",
    "print(librosa.istft(np.array([p3]*3).reshape(-1,3), hop_length=1, win_length=3))\n",
    "print(librosa.istft(np.array([p4]*3).reshape(-1,3), hop_length=1, win_length=3))\n",
    "print(librosa.istft(np.array([p5]*3).reshape(-1,3), hop_length=1, win_length=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
