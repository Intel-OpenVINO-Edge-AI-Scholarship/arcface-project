{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Can't import tf2onnx module, so the conversion on a model with any custom/lambda layer will fail!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras2onnx\n",
    "import onnxruntime\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.datasets import mnist\n",
    "from metrics_face import *\n",
    "import tensorflow.compat.v1 as tf\n",
    "from glob import glob\n",
    "import os\n",
    "import facenet\n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aswin/anaconda3/envs/enscalo_test/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y), (X_test, y_test) = mnist.load_data()\n",
    "X = X[:, :, :, np.newaxis].astype('float32') / 255\n",
    "X_test = X_test[:, :, :, np.newaxis].astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    img = image.load_img(img_path, target_size=(160, 160))\n",
    "    return np.expand_dims(np.asarray(img),axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, nrof_classes = facenet.get_dataset(\"vggface2_train_2/train\")\n",
    "path_exp = os.path.expanduser(\"vggface2_train_2/train\")\n",
    "image_paths = [glob(os.path.join(path_exp, classes[i], \"*.jpg\")) for i in range(nrof_classes)]\n",
    "split = int(round(nrof_classes*(1-0.99)))\n",
    "X_test = paths_to_tensor([image_paths[0][0],image_paths[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:01<00:00, 15.88it/s]\n"
     ]
    }
   ],
   "source": [
    "classes, nrof_classes = facenet.get_dataset(\"../datasets/vggface2_test_2/test\")\n",
    "nrof_classes = 30\n",
    "np.random.shuffle(classes)\n",
    "path_exp = os.path.expanduser(\"../datasets/vggface2_test_2/test\")\n",
    "image_paths = [sorted(glob(os.path.join(path_exp, classes[i], \"*.jpg\")))[3:4] for i in range(nrof_classes)]\n",
    "images = []\n",
    "image_paths = np.array(image_paths).flatten().tolist()\n",
    "for img_path in tqdm(image_paths):\n",
    "    img = Image.open(img_path).convert('L')\n",
    "    face_cascade = cv2.CascadeClassifier('/usr/share/opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "    img = np.asarray(img)\n",
    "    faces_multi = face_cascade.detectMultiScale(img, 1.1, 4)\n",
    "    faces = [face.astype(np.int64).tolist() for face in faces_multi]\n",
    "    if len(faces) > 0:\n",
    "        yes_face = faces[0]\n",
    "        img = cv2.resize(img[yes_face[1]:yes_face[1]+yes_face[3],yes_face[0]:yes_face[0]+yes_face[2]],(160,160))\n",
    "        images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_model = load_model('models/mnist_vgg8_arcface_5d/model_sm.hdf5', custom_objects={'ArcFace': ArcFace})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/29 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 277ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 1/29 [00:00<00:13,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 5/29 [00:00<00:08,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 9/29 [00:00<00:05,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▍     | 13/29 [00:00<00:03,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 18/29 [00:00<00:01,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|███████▌  | 22/29 [00:01<00:00,  9.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████▉ | 26/29 [00:01<00:00, 12.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29/29 [00:01<00:00, 22.84it/s]\n"
     ]
    }
   ],
   "source": [
    "arcface_model1 = Model(inputs=arcface_model.input[0], outputs=arcface_model.layers[-4].output)\n",
    "arcface_features1_array = []\n",
    "for img in tqdm(images):\n",
    "    arcface_features1 = arcface_model1.predict(img.reshape(1,160,160,1), verbose=1)\n",
    "    arcface_features1_array.append(arcface_features1/np.linalg.norm(arcface_features1, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 110.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.12863761  0.76236928 -0.13255814 54.14560795  4.81521785]]\n",
      "[[ 0.15975255  1.33300948  0.18358797 27.40246773  1.08094156]]\n",
      "[[ 3.1481061   0.43887106  2.86171556  6.6575712  30.26175976]]\n",
      "[[ 0.30483395  0.13814609  2.17786789 28.44579458 20.61951399]]\n",
      "[[ 2.45321512  0.27277893  2.44689369 25.40250301 37.3195672 ]]\n",
      "[[ 0.08486605  1.30437589  0.12468302 35.86837769  5.72795033]]\n",
      "[[ 0.14659351  2.2985568   0.21995139 20.58241606  4.15587276]]\n",
      "[[ 0.12663314  0.630427    0.36587846 52.0238781  19.80523825]]\n",
      "[[ 3.72222924  3.23607779  3.44074297  6.32288694 23.47439051]]\n",
      "[[ 5.28120995e-03  2.34166592e-01  1.62659109e-01  6.29423046e+01\n",
      "  -2.05354244e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class_weights = [1, 0.5, 1, 10, 10]\n",
    "def intermediate_model(x):\n",
    "    return (keras.activations.elu((x-keras.backend.mean(x, axis=1))/keras.backend.square(keras.backend.std(x)))+\\\n",
    "    keras.backend.square(x-keras.backend.mean(x, axis=1))/keras.backend.std(x)) + \\\n",
    "keras.backend.min(x, axis=1) * keras.backend.log(keras.backend.square(x-keras.backend.mean(x, axis=1)))\n",
    "intermediary_array = []\n",
    "for i in tqdm(range(len(images))):\n",
    "    a = np.multiply(class_weights, intermediate_model(\n",
    "        tf.convert_to_tensor(tf.convert_to_tensor(arcface_features1_array[i], dtype=tf.float32))).numpy())\n",
    "    if i < 10:\n",
    "        print(a)\n",
    "    intermediary_array.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xc2 in position 2: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-41b0b70c029b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"models/retina-net-R-101-FPN/model_final.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc2 in position 2: ordinal not in range(128)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediary_array = np.dstack(intermediary_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ 0.11949151, -0.7965891 ,  0.26912665,  0.44944108,  0.27702197]\n",
    "[ 0.1343845 , -0.6959256 ,  0.10052601, -0.57591254,  0.39477533]\n",
    "[-0.20688158,  0.79289556, -0.17721854,  0.4884938 , -0.24183482]\n",
    "[-0.23509903,  0.7068529 , -0.20450296,  0.50083554, -0.39042255]\n",
    "[-0.27845502,  0.6834492 , -0.0885547 , -0.2526008 , -0.61944395]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = arcface_model.layers[-3].weights[0]\n",
    "beta = arcface_model.layers[-3].weights[1]\n",
    "moving_mean = arcface_model.layers[-3].weights[2]\n",
    "moving_variance = arcface_model.layers[-3].weights[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.0452649 ,  0.12484039,  0.11293622,  0.68007135,  0.11994109],\n",
       "       dtype=float32),\n",
       " array([-1.3400202 , -0.639355  ,  7.2867208 , -0.77025115, -0.94090235],\n",
       "       dtype=float32),\n",
       " array([-6.1528773, 11.898168 , 11.309967 , 27.529154 , -2.9971893],\n",
       "       dtype=float32),\n",
       " array([ 3716.3535, 23182.342 ,  4701.81  , 16304.691 ,  8035.857 ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma.numpy(), beta.numpy(), moving_mean.numpy(), moving_variance.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.007397 , -0.0035678,  0.0399859, -0.0034578, -0.0051191],\n",
       "       [-0.0073982, -0.0035652,  0.0399887, -0.0042414, -0.0051466],\n",
       "       [-0.0074104, -0.0035692,  0.040013 , -0.0048493, -0.0049318],\n",
       "       [-0.0073988, -0.0035706,  0.0400068, -0.0042109, -0.0050027],\n",
       "       [-0.0074076, -0.00357  ,  0.0400092, -0.0043   , -0.0048798],\n",
       "       [-0.0073979, -0.0035653,  0.0399882, -0.0039934, -0.0051124],\n",
       "       [-0.0073982, -0.0035609,  0.039989 , -0.0044413, -0.0051239],\n",
       "       [-0.0073981, -0.0035684,  0.0399904, -0.00352  , -0.0050087],\n",
       "       [-0.0074128, -0.0035566,  0.0400182, -0.0048591, -0.0049817],\n",
       "       [-0.0073976, -0.0035702,  0.0399885, -0.0032   , -0.0051696],\n",
       "       [-0.007397 , -0.0035715,  0.0399926, -0.0033236, -0.005036 ],\n",
       "       [-0.0074146, -0.003566 ,  0.0400081, -0.0041475, -0.0051197],\n",
       "       [-0.0074074, -0.0035694,  0.0400048, -0.0048247, -0.0050123],\n",
       "       [-0.0073975, -0.0035708,  0.0400062, -0.003274 , -0.0051659],\n",
       "       [-0.0074062, -0.0035656,  0.0400365, -0.0048022, -0.0048788],\n",
       "       [-0.0073987, -0.0035642,  0.03999  , -0.0042948, -0.0051411],\n",
       "       [-0.0074002, -0.003563 ,  0.039993 , -0.0043189, -0.0051317],\n",
       "       [-0.0073988, -0.0035645,  0.0399893, -0.0042831, -0.0050688],\n",
       "       [-0.0074144, -0.00357  ,  0.0400134, -0.0044746, -0.0048796],\n",
       "       [-0.0073958, -0.0035722,  0.0399877, -0.0033273, -0.005098 ],\n",
       "       [-0.0074225, -0.0035704,  0.0400094, -0.0049079, -0.004844 ],\n",
       "       [-0.0073982, -0.0035654,  0.0399889, -0.0049844, -0.0049474],\n",
       "       [-0.0074066, -0.0035699,  0.0400068, -0.0047484, -0.0049759],\n",
       "       [-0.0073961, -0.0035719,  0.0399857, -0.0039074, -0.0049706],\n",
       "       [-0.0073988, -0.0035707,  0.0400097, -0.0044834, -0.0049038]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xNorm = (intermediary_array[0,:,:] - moving_mean.numpy().reshape(-1,1)) / np.sqrt(0.001 + moving_variance.numpy().reshape(-1,1))\n",
    "data = gamma.numpy().reshape(-1,1) * xNorm + beta.numpy().reshape(-1,1)\n",
    "np.round(data.T/np.linalg.norm(data.T,1),7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_features2_array = np.dstack(arcface_features2_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_model2 = Model(inputs=arcface_model.input[0], outputs=arcface_model.layers[-3].output)\n",
    "arcface_features2_array = []\n",
    "for img in tqdm(images):\n",
    "    arcface_features2 = arcface_model2.predict(img.reshape(1,160,160,1), verbose=1)\n",
    "    arcface_features2_array.append(arcface_features2/np.linalg.norm(arcface_features2, axis=1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = [-0.176519  , -0.105028  ,  0.95071614, -0.21184155, -0.09524728]\n",
    "p2 = [-0.17389667, -0.10519306,  0.93706113, -0.26787877, -0.09408321]\n",
    "p3 = [-0.17534307, -0.09559851,  0.9498372 , -0.2157349 , -0.1066931 ]\n",
    "p4 = [-0.17858912, -0.09505837,  0.9690808 , -0.09122588, -0.10784248]\n",
    "p5 = [-0.17978127, -0.1065986 ,  0.9706176 , -0.04294081, -0.11123333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(librosa.istft(np.dstack([p1]*5).reshape(-1,5), hop_length=1, win_length=1))\n",
    "print(librosa.istft(np.dstack([p2]*5).reshape(-1,5), hop_length=1, win_length=1))\n",
    "print(librosa.istft(np.dstack([p3]*5).reshape(-1,5), hop_length=1, win_length=1))\n",
    "print(librosa.istft(np.dstack([p4]*5).reshape(-1,5), hop_length=1, win_length=1))\n",
    "print(librosa.istft(np.dstack([p5]*5).reshape(-1,5), hop_length=1, win_length=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from pandas.plotting import andrews_curves\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# Look pretty...\n",
    "matplotlib.style.use('ggplot')\n",
    "# If the above line throws an error, use plt.style.use('ggplot') instead\n",
    "\n",
    "# Load up SKLearn's Iris Dataset into a Pandas Dataframe\n",
    "class_weights = [0.1, 0.5, 0.1, 1, 1]\n",
    "df = pd.DataFrame(\n",
    "    np.multiply(class_weights, \n",
    "      np.exp(arcface_features1_array-np.expand_dims(arcface_features1_array.mean(axis=1),1)/\\\n",
    "      np.expand_dims(arcface_features1_array.std(axis=1),1)) + \\\n",
    "    np.expand_dims(arcface_features1_array.mean(axis=1),1)\n",
    "   ), columns=['col1','col2','col3','col4','col5'])\n",
    "df['target_names'] = [librosa.istft(\n",
    "    np.dstack([df.iloc[i,:].values]*5).reshape(-1,5), hop_length=1, win_length=1\n",
    ").mean() for i in range(len(df))]\n",
    "# Andrews Curves Start Here:\n",
    "plt.figure()\n",
    "andrews_curves(df, 'target_names')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[-0.17978127, -0.1065986 ,  0.9706176 , -0.04294081, -0.11123333]\n",
    "[-0.17668884, -0.11009184,  0.93734115, -0.26282188, -0.09474736]\n",
    "[-0.1755625 , -0.05969939,  0.97241575, -0.011096  , -0.14106144]\n",
    "[-0.17391324, -0.05885269,  0.9708331 ,  0.01058049, -0.15382384]\n",
    "[-0.17508644, -0.07741634,  0.96141636, -0.14232956, -0.13701247]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = [-0.176519  , -0.105028  ,  0.95071614, -0.21184155, -0.09524728]\n",
    "p2 = [-0.17389667, -0.10519306,  0.93706113, -0.26787877, -0.09408321]\n",
    "p3 = [-0.17534307, -0.09559851,  0.9498372 , -0.2157349 , -0.1066931 ]\n",
    "p4 = [-0.17858912, -0.09505837,  0.9690808 , -0.09122588, -0.10784248]\n",
    "p5 = [-0.17978127, -0.1065986 ,  0.9706176 , -0.04294081, -0.11123333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from pandas.tools.plotting import andrews_curves\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# Look pretty...\n",
    "matplotlib.style.use('ggplot')\n",
    "# If the above line throws an error, use plt.style.use('ggplot') instead\n",
    "\n",
    "# Load up SKLearn's Iris Dataset into a Pandas Dataframe\n",
    "data = load_iris()\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target_names'] = [data.target_names[i] for i in data.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(arcface_features2_array, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagehash.average_hash(\n",
    "    Image.open(\"vggface2_test/test/n000029/0130_01.jpg\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagehash, cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(1580, 862),\n",
    "        batch_size=32)\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(1580, 862),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure()\n",
    "ax2 = Axes3D(fig2)\n",
    "for c in range(len(np.unique(y_test))):\n",
    "    ax2.plot(arcface_features[y_test==c, 0], arcface_features[y_test==c, 1], arcface_features[y_test==c, 2], '.', alpha=0.1)\n",
    "plt.title('ArcFace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arcface_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(librosa.istft(np.array([p1]*3).reshape(-1,3), hop_length=1, win_length=3))\n",
    "print(librosa.istft(np.array([p2]*3).reshape(-1,3), hop_length=1, win_length=3))\n",
    "print(librosa.istft(np.array([p3]*3).reshape(-1,3), hop_length=1, win_length=3))\n",
    "print(librosa.istft(np.array([p4]*3).reshape(-1,3), hop_length=1, win_length=3))\n",
    "print(librosa.istft(np.array([p5]*3).reshape(-1,3), hop_length=1, win_length=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
