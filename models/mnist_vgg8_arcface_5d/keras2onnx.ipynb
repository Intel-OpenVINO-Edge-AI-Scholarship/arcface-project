{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Can't import tf2onnx module, so the conversion on a model with any custom/lambda layer will fail!\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0424 22:09:41.696109 140470669856128 wrapper.py:21] Can't import tf2onnx module, so the conversion on a model with any custom/lambda layer will fail!\n",
      "W0424 22:09:41.800404 140470669856128 deprecation.py:323] From /home/aswin/anaconda3/envs/enscalo_test/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras2onnx\n",
    "import onnxruntime\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.datasets import mnist\n",
    "from metrics import *\n",
    "import tensorflow.compat.v1 as tf\n",
    "from glob import glob\n",
    "import os\n",
    "import facenet\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y), (X_test, y_test) = mnist.load_data()\n",
    "X = X[:, :, :, np.newaxis].astype('float32') / 255\n",
    "X_test = X_test[:, :, :, np.newaxis].astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    img = image.load_img(img_path, target_size=(160, 160))\n",
    "    return np.expand_dims(np.asarray(img),axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in img_paths]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, nrof_classes = facenet.get_dataset(\"vggface2_train_2/train\")\n",
    "path_exp = os.path.expanduser(\"vggface2_train_2/train\")\n",
    "image_paths = [glob(os.path.join(path_exp, classes[i], \"*.jpg\")) for i in range(nrof_classes)]\n",
    "split = int(round(nrof_classes*(1-0.99)))\n",
    "X_test = paths_to_tensor([image_paths[0][0],image_paths[0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(None, 5), (None, 86)]\n",
      "2/2 [==============================] - 0s 155ms/step\n"
     ]
    }
   ],
   "source": [
    "arcface_model = load_model('models/mnist_vgg8_arcface_5d/model.hdf5', custom_objects={'ArcFace': ArcFace})\n",
    "arcface_model = Model(inputs=arcface_model.input[0], outputs=arcface_model.layers[-3].output)\n",
    "arcface_features = arcface_model.predict(X_test, verbose=1)\n",
    "arcface_features /= np.linalg.norm(arcface_features, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vggface2_train_2', 'train', 'n000002', '0161_01.jpg']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths[0][0].split(\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure()\n",
    "ax2 = Axes3D(fig2)\n",
    "for c in range(len(np.unique(y_test))):\n",
    "    ax2.plot(arcface_features[y_test==c, 0], arcface_features[y_test==c, 1], arcface_features[y_test==c, 2], '.', alpha=0.1)\n",
    "plt.title('ArcFace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(1580, 862),\n",
    "        batch_size=32)\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(1580, 862),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagehash, cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagehash.average_hash(\n",
    "    Image.open(\"vggface2_test/test/n000029/0130_01.jpg\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from mtcnn import MTCNN\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"vggface2_test_2/test/n000029/0130_01.jpg\").convert('L')\n",
    "face_cascade = cv2.CascadeClassifier('/usr/share/opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "faces_multi = face_cascade.detectMultiScale(np.asarray(img), 1.3, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
